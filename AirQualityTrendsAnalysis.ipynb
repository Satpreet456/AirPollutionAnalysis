{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to pre-process 2017-2019 air quality data to make ready for visualization\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "os.chdir('E:/Research/Processing Datasets/Air quality datasets')\n",
    "count = 0\n",
    "studyPeriodFiles = []\n",
    "#Store filenames of files in 2017-2019\n",
    "for ind, filename in enumerate(os.listdir(os.getcwd())):\n",
    "    splits = filename.split(\"_\")\n",
    "    if splits[3] in ['2017', '2018', '2019']:\n",
    "        studyPeriodFiles.append(filename)\n",
    "print(len(studyPeriodFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "start = time.process_time()\n",
    "os.chdir('E:/Research/Processing Datasets/Air quality datasets')\n",
    "airQualityData = []\n",
    "count = 0\n",
    "substart = time.process_time()\n",
    "#Process each file\n",
    "for ind, filename in enumerate(studyPeriodFiles[11:]):\n",
    "    count+=1\n",
    "    #To print status\n",
    "    if count%1000 == 0:\n",
    "        print('Procesed until ', count,'/',len(studyPeriodFiles),' in ',time.process_time() - substart)\n",
    "        substart = time.process_time()\n",
    "    try:\n",
    "        splits = filename.split(\"_\")\n",
    "        try:\n",
    "            df = pd.read_csv(filename, error_bad_lines=False, encoding = \"utf-16\")\n",
    "        except UnicodeError:\n",
    "            df = pd.read_csv(filename, error_bad_lines=False)\n",
    "        \n",
    "        #Filter invalid data\n",
    "        stationCodes = [code for code in df['AirQualityStationEoICode'].unique() if type(code)==str]\n",
    "        pollutants = [pol for pol in df['AirPollutant'].unique() if type(pol)==str and not pol.replace('.', '').isdigit()]\n",
    "        avgTimes = [time for time in df['AveragingTime'].unique() if type(time)==str]\n",
    "        UOMs = [uni for uni in df['UnitOfMeasurement'].unique() if type(uni) == str and re.search('[a-zA-Z]', uni)]\n",
    "        \n",
    "        #Process records\n",
    "        if len(stationCodes) > 0:\n",
    "            temp = df[(df['AirQualityStationEoICode'].isin(stationCodes)) & (df['AirPollutant'].isin(pollutants)) & (df['AveragingTime'].isin(avgTimes)) & (df['UnitOfMeasurement'].isin(UOMs))]\n",
    "            temp['DateBegin'] = pd.to_datetime(temp['DatetimeBegin']).dt.date\n",
    "            temp['Concentration'] = temp['Concentration'].astype(float)\n",
    "                \n",
    "            for avgTime in avgTimes:\n",
    "                #Find daily mean of hourly reading\n",
    "                groupedDf = temp[temp['AveragingTime'] == avgTime].groupby(['Countrycode','AirQualityStationEoICode', 'DateBegin', 'AirPollutant', 'UnitOfMeasurement','AveragingTime'], as_index=False).agg({'Concentration': 'mean'})\n",
    "                #airQualityData.extend(groupedDf.to_dict('records'))\n",
    "                #Append after the file was created\n",
    "                #Append to csv file\n",
    "                groupedDf.to_csv('D:/AirQualityDataset/AirQualityStudyPeriodDataNew.csv', mode='a', header=False, index = False, columns=['Countrycode', 'AirPollutant', 'AirQualityStationEoICode', 'AveragingTime','DateBegin','Concentration', 'UnitOfMeasurement'])\n",
    "                \n",
    "    except Exception:\n",
    "        print('Exception while processing file ', ind, ' - ', filename)\n",
    "        print(traceback.format_exc())\n",
    "        continue\n",
    "\n",
    "#Create new file using first 10 files\n",
    "#pd.DataFrame(airQualityData).to_csv('D:/AirQualityDataset/AirQualityStudyPeriodDataNew.csv', index = False, columns=['Countrycode', 'AirPollutant', 'AirQualityStationEoICode', 'AveragingTime','DateBegin','Concentration', 'UnitOfMeasurement'])\n",
    "print(\"Completed processing in \", time.process_time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to produce formatted data for visualizations\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "#Read the data produced by above script(Around 500MB)\n",
    "df = pd.read_csv('AirQualityStudyPeriodDataNew.csv')\n",
    "df = df[df['AirPollutant'].isin(['CO', 'SO2', 'C6H6', 'PM10', 'PM2.5', 'O3', 'NO2'])]\n",
    "#extract year\n",
    "df['Year'] = pd.to_datetime(df['DateBegin']).dt.year\n",
    "\n",
    "#Create boolean for exceeding EU standard limits for each pollutant\n",
    "df['Concentration'] = pd.to_numeric(df['Concentration'],errors='coerce')\n",
    "df['ExceededLimitCO'] = np.where(((df.AirPollutant == 'CO') & (df.AveragingTime.isin(['hour', 'day', 'var', 'fortnight'])) & (df.Concentration > 7.0)), True, False)\n",
    "df['ExceededLimitC6H6'] = np.where(((df.AirPollutant == 'C6H6') & (df.AveragingTime == 'year') & (df.Concentration > 3.5)), True, False)\n",
    "df['ExceededLimitSO2'] = np.where(((df.AirPollutant == 'SO2') & (df.AveragingTime.isin(['hour', 'day', 'var', 'fortnight']))& (df.Concentration > 75.0)), True, False)\n",
    "df['ExceededLimitPM2'] = np.where(((df.AirPollutant == 'PM2.5') & (df.AveragingTime.isin(['hour', 'var', 'day', 'fortnight', 'year'])) & (df.Concentration > 25.0)), True, False)\n",
    "df['ExceededLimitPM10'] = np.where(((df.AirPollutant == 'PM10') & (df.AveragingTime.isin(['hour', 'var', 'day', 'fortnight'])) & (df.Concentration > 50.0)), True, np.where(((df.AirPollutant == 'PM10') & (df.AveragingTime =='year') & (df.Concentration > 40.0)), True, False))\n",
    "df['ExceededLimitO3'] = np.where(((df.AirPollutant == 'O3') & (df.AveragingTime.isin(['hour', 'var', 'day', 'fortnight'])) & (df.Concentration > 120.0)), True, False)\n",
    "df['ExceededLimitNO2'] = np.where(((df.AirPollutant == 'NO2') & (df.AveragingTime.isin(['hour', 'var', 'day', 'fortnight'])) & (df.Concentration > 200.0)), True, np.where(((df.AirPollutant == 'NO2') & (df.AveragingTime == 'year') & (df.Concentration > 40.0)), True, False))\n",
    "\n",
    "#Finally create one boolean for all the pollutants\n",
    "df['Exceeded'] = np.where(((df.ExceededLimitCO == True) | (df.ExceededLimitC6H6 == True) | (df.ExceededLimitSO2 == True) | (df.ExceededLimitPM2 == True) | (df.ExceededLimitPM10 == True) | (df.ExceededLimitO3 == True) | (df.ExceededLimitNO2 == True) ), True, False )\n",
    "                                   \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract counts of times the limit has been exceeded for each pollutant\n",
    "exceedingPollutantsDF = df.groupby(['AirPollutant', 'Year']).apply(lambda x: len(x['Exceeded'] == True)).reset_index()\n",
    "exceedingDF.to_csv(\"pollutantExceedingData.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract counts of times the limit has been exceeded for each country\n",
    "exceedingCountriesDF = df.groupby(['Countrycode']).apply(lambda x: len(x['Exceeded'] == True)).reset_index()\n",
    "exceedingCountriesDF.to_csv(\"countryExceedingData.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Script to merge with Air Quality Locations dataset to add geo-co-ordinate values\n",
    "\n",
    "#Read locations data\n",
    "stations = pd.read_csv('AirQualityStations.csv')\n",
    "#Extract needed columns, drop na and duplicates\n",
    "stations = stations[['EoICode', 'CountryOrTerritory','Latitude', 'Longitude']].dropna(subset=['Latitude', 'Longitude']).drop_duplicates('EoICode')\n",
    "#rename common column to make ready for merge\n",
    "stations.rename(columns={'EoICode': 'AirQualityStationEoICode'}, inplace=True)\n",
    "#filter out stations that do not have location co-ordinates\n",
    "locationBased = df[df['AirQualityStationEoICode'].isin(stations['AirQualityStationEoICode'].values)]\n",
    "#Merge datasets\n",
    "locationBased = pd.merge(locationBased, stations, on='AirQualityStationEoICode')\n",
    "\n",
    "#Extract counts of times the limit has been exceeded for each station\n",
    "exceedingstations =locationBased.groupby(['CountryOrTerritory','AirQualityStationEoICode', 'Latitude', 'Longitude']).apply(lambda x: len(x['Exceeded'] == True)).reset_index()\n",
    "exceedingstations.rename(columns={0:'exceedCount'}, inplace=True )\n",
    "#Store in file\n",
    "exceedingstations.to_csv('exceedingstations.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
